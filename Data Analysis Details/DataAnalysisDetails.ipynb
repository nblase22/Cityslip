{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CitySlip -- Data Analysis Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Zipcodes\n",
    "A user enters a zip code, and the Python zipcodes package provides the city, state and lat/long. We first verify that the zip code actually represents a real location and not just a PO box or military APO by comparing the input ZIP to a free ZIP code CSV file (free-zipcode-database-Primary.csv).\n",
    "\n",
    "Depending on the data we were retrieving, we used either the zip code or the lat/long coordinate as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Data\n",
    "\n",
    "Onboard Informatics provides an API with access to property data, community, and school data. The community data contains demographic data and all sorts of statistics about a location (either zip code or lat/long coordinate). \n",
    "\n",
    "The data provided in the Community API is aggregated from a variety of public and private sources including:\n",
    "\n",
    "The U.S. Census and other government agencies. USGS, EPA, FBI and local crime agencies. American Community Survey, Bureau of Economic Analysis, Bureau of Labor Statistics, Bureau of Transportation Statistics, CDC, Department of Defense, Federal Aviation Administration,Federal Financial Institutions Examination Council, Federal Housing Finance, IRS, NCES, National Center for Health Statistics, National Parks Service, Social Security, USPS, Mediamark Consumer Survey, Applied Geographic Solutions, School Digger, and Niche.\n",
    "\n",
    "We selected the following pieces of info about the zip code:\n",
    "\n",
    "a) Crime Risk\n",
    "\n",
    "b) Sales Tax Rate\n",
    "\n",
    "c) Average Temperature in January\n",
    "\n",
    "d) Average Temperature in July\n",
    "\n",
    "e) Age Demographics\n",
    "\n",
    "We use the Onboard API, which is via HTTP connection. The request calls used a different syntax than what we were used to from Google, Twitter, etc. Formatting the URL is very similar, but the API key is stored in a header dictionary.  Onboard API documentation - https://www.onboardinformatics.com\n",
    "\n",
    "### Request\n",
    "    import http.client\n",
    "    conn = http.client.HTTPSConnection(\"search.onboard-apis.com\")\n",
    "    headers = {\n",
    "        'accept': \"application/json\",\n",
    "        'apikey': \"xxxxxxxxxxxxxxyyyyyyyyyyyyyyyyyyyy\",\n",
    "        } \n",
    "\n",
    "    community_url = \"/communityapi/v2.0.0/Area/Full/?\"\n",
    "    queries=\"AreaId=ZI\"+target_zip\n",
    "    query_url = community_url + queries\n",
    "    conn.request(\"GET\", query_url, headers=headers) \n",
    "    res = conn.getresponse()\n",
    "    resp = json.loads(res.read())\n",
    "\n",
    "\n",
    "\n",
    "### Response\n",
    "\n",
    "The response returned is a very large JSON structure with hundreds of data points. One example of a field we used is:\n",
    "\n",
    "    crime = resp['response']['result']['package']['item'][0]['crmcytotc']\n",
    "\n",
    "From the response, age groups and numbers of people in those groups were stored in a DataFrame and plotted in a pie chart. We stored the other fields in a dictionary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points of Interest (POIs)\n",
    "\n",
    "We used the Google MAPs API to find the number of various points of interest within 5 miles of the lat/long coordinate. We selected the following POIs:\n",
    "\n",
    "a) liquor_stores\n",
    "\n",
    "b) gyms\n",
    "\n",
    "c) parks\n",
    "\n",
    "d) shopping_malls\n",
    "\n",
    "e) grocery stores or supermarkets \n",
    "\n",
    "f) movie_theaters\n",
    "\n",
    "We created the target urls and used requests to gather the necessary data, and then counted them. This is similar to a class exercise.\n",
    "\n",
    "            target_url = \"https://maps.googleapis.com/maps/api/place/radarsearch/json\" \\\n",
    "                \"?types=%s&location=%s,%s&radius=%s&key=%s\" % (\n",
    "                    target, target_area[\"lat\"], target_area[\"lng\"], target_radius, gkey)\n",
    "\n",
    "            places_data = req.get(target_url).json()\n",
    "\n",
    "            # use the len function to find the count of results\n",
    "            numbers = len(places_data[\"results\"])\n",
    "            \n",
    "We created a pie chart with the POIs.            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Data\n",
    "\n",
    "We used a census API to get the county and state for the input lat/long coordinate. Then we read a CSV file with census data to get the population for the county for years 2010-2016. A graph shows the change in population.\n",
    "\n",
    "     API Info (No Key Required):  https://www.fcc.gov/general/census-block-conversions-api\n",
    "     cen_block_url = ('http://data.fcc.gov/api/block/find?format=json&latitude=%s&longitude=%s&showall=true' % \n",
    "         (lat, lng))\n",
    "     lat_lon_county = req.get(cen_block_url).json()\n",
    "     county_name = lat_lon_county['County']['name']\n",
    "     state_name = lat_lon_county['State']['name']\n",
    "     county_census_pop = pd.read_csv('Resources/co-est2016-alldata.csv',\\\n",
    "                                encoding=\"ISO-8859-1\").apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Estate Data (Zillow)\n",
    "\n",
    "Zillow's API returns an XML response, rather than a JSON response. Instead of using the API, we decided to use Zillow CSV files:\n",
    "\n",
    "MarketHealthIndex_Zip.csv -- provides an index about real estate market health of a zip code\n",
    "\n",
    "Zip_Zhvi_AllHomes.csv -- provides home values by zip code by month for many years. We chose to use data from 2014 on because some zip codes did not contain data prior to 2014.\n",
    "\n",
    "Zip_Zri_AllHomes.csv -- provides monthly rent data by zip code by month for many years. We chose to use data from 2014 on because some zip codes did not contain data prior to 2014.\n",
    "\n",
    "These files were read into dataframes. In addition to gathering home value and monthly rent for the input zip code, we also calculated the mean home value and monthly rent of the entire database for the most recent month (Sept 2017). We used that later in the score calculation.\n",
    "\n",
    "If Zillow didn't have data for the input zip code, we found surrounding zip codes using the Python zipcodes package, and averaged the values for those zip codes.\n",
    "\n",
    "We plotted both home values and monthly rents for the input zip code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Data\n",
    "\n",
    "We used Onboard's API for schools to return the number of each type of schools within a radius of a lat/long coordinate. Onboard has data for public, private and Catholic schools. \n",
    "\n",
    "We use the Onboard API, which is via HTTP connection. The request calls used a different syntax than what we were used to from Google, Twitter, etc. Formatting the URL is very similar, but the API key is stored in a header dictionary.  Onboard API documentation - https://www.onboardinformatics.com\n",
    "\n",
    "### Request\n",
    "\n",
    "    conn = http.client.HTTPSConnection(\"search.onboard-apis.com\") \n",
    "    school_url = \"/propertyapi/v1.0.0/school/snapshot?\"\n",
    "    headers = { \n",
    "        'accept': \"application/json\", \n",
    "        'apikey': \"xxxxxxxxxxxxxxyyyyyyyyyyyyyyyyyyyy\", \n",
    "        } \n",
    "\n",
    "    point = \"latitude=\" + str(lat) + \"&longitude=\" + str(lng) + \"&radius=\" + str(radius)\n",
    "    query_url = school_url + point + \"&pageSize=\" + str(page_size)\n",
    " \n",
    "    #print(query_url)\n",
    "    \n",
    "    #request the first page of school data\n",
    "    conn.request(\"GET\", query_url, headers=headers) \n",
    "\n",
    "    res = conn.getresponse()\n",
    "    resp = json.loads(res.read())\n",
    "    \n",
    "### Response\n",
    "    \n",
    "    sch_type = resp['school'][i]['School']['Filetypetext']\n",
    "    \n",
    "We plotted the types of schools in a bar chart.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkability \n",
    "\n",
    "We used the Walkscore API to find out how walkable (pedestrian-friendly) a zip code is. \n",
    "\n",
    "Walkscore API â€“ https://www.walkscore.com/professional/api.php\n",
    "\n",
    "### Request\n",
    "    walk_api_key = \"ca8240c847695f334874949c406f04aa\"\n",
    "    walk_url = \"http://api.walkscore.com/score?format=json&\"\n",
    "    \n",
    "    query_url = walk_url  + \"&lat=\" + str(lat) + \"&lon=\" + str(lng) + \"&transit=1&bike=1\" + \"&wsapikey=\" + walk_api_key\n",
    "    walk_response = req.get(query_url).json()\n",
    "\n",
    "### Response\n",
    "    walk_score = walk_response['walkscore']\n",
    "    walk_description=walk_response['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CitySlip Score\n",
    "\n",
    "After retrieving all the above data and demographics, we used weighting factors for each to compute a score (range 0-100) for the input zip code. \n",
    "\n",
    "We stored the zip code, city, state, county and all the score components along with the date executed in a CSV file.\n",
    "\n",
    "A future enhancement for additional analysis would be to plot the scores either in a scatter plot and/or a line plot, grouped by state. \n",
    "\n",
    "If this were a real product, we could track how a score changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
